{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Выберем алгоритм SGNS, поскольку из результатов статьи следует, что именно этот алгоритм лучше всего выявляет семантические сдвиги",
   "id": "2155860daa7462e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T22:04:36.497609Z",
     "start_time": "2025-04-12T22:04:29.228554Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install matplotlib",
   "id": "90e4accfe7403b37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\r\n",
      "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/da/36/236fbd868b6c91309a5206bd90c3f881f4f44b2d997cd1d6239ef652f878/matplotlib-3.9.4-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached matplotlib-3.9.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (11 kB)\r\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\r\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/ec/22/19f5b948367ab5260fb41d842c7a78dae645603881ea6bc39738bcfcabf6/contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.4 kB)\r\n",
      "Collecting cycler>=0.10 (from matplotlib)\r\n",
      "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\r\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\r\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/d2/c7/3bddafbb95447f6fbabdd0b399bf468649321fd4029e356b4f6bd70fbc1b/fonttools-4.57.0-cp39-cp39-macosx_10_9_universal2.whl.metadata\r\n",
      "  Using cached fonttools-4.57.0-cp39-cp39-macosx_10_9_universal2.whl.metadata (102 kB)\r\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\r\n",
      "  Obtaining dependency information for kiwisolver>=1.3.1 from https://files.pythonhosted.org/packages/8a/be/a6ae58978772f685d48dd2e84460937761c53c4bbd84e42b0336473d9775/kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23 in ./venv/lib/python3.9/site-packages (from matplotlib) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from matplotlib) (24.2)\r\n",
      "Collecting pillow>=8 (from matplotlib)\r\n",
      "  Obtaining dependency information for pillow>=8 from https://files.pythonhosted.org/packages/b6/4d/dcb7a9af3fc1e8653267c38ed622605d9d1793349274b3ef7af06457e257/pillow-11.2.1-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading pillow-11.2.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (8.9 kB)\r\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\r\n",
      "  Obtaining dependency information for pyparsing>=2.3.1 from https://files.pythonhosted.org/packages/05/e7/df2285f3d08fee213f2d041540fa4fc9ca6c2d44cf36d3a035bf2a8d2bcc/pyparsing-3.2.3-py3-none-any.whl.metadata\r\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\r\n",
      "  Obtaining dependency information for importlib-resources>=3.2.0 from https://files.pythonhosted.org/packages/a4/ed/1f1afb2e9e7f38a545d628f864d562a5ae64fe6f7a10e28ffb9b185b4e89/importlib_resources-6.5.2-py3-none-any.whl.metadata\r\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\r\n",
      "Using cached matplotlib-3.9.4-cp39-cp39-macosx_11_0_arm64.whl (7.8 MB)\r\n",
      "Using cached contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl (249 kB)\r\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\r\n",
      "Using cached fonttools-4.57.0-cp39-cp39-macosx_10_9_universal2.whl (2.8 MB)\r\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\r\n",
      "Using cached kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl (64 kB)\r\n",
      "Downloading pillow-11.2.1-cp39-cp39-macosx_11_0_arm64.whl (3.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.0/3.0 MB\u001B[0m \u001B[31m1.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\r\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\r\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.57.0 importlib-resources-6.5.2 kiwisolver-1.4.7 matplotlib-3.9.4 pillow-11.2.1 pyparsing-3.2.3\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 252
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-12T13:00:41.647108Z",
     "start_time": "2025-04-12T13:00:40.709978Z"
    }
   },
   "source": [
    "from gensim.models.word2vec import LineSentence\n",
    "!pip install gensim\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in ./venv/lib/python3.9/site-packages (4.3.3)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in ./venv/lib/python3.9/site-packages (from gensim) (1.26.4)\r\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in ./venv/lib/python3.9/site-packages (from gensim) (1.13.1)\r\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./venv/lib/python3.9/site-packages (from gensim) (7.1.0)\r\n",
      "Requirement already satisfied: wrapt in ./venv/lib/python3.9/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T17:35:14.839009Z",
     "start_time": "2025-04-12T17:35:14.022722Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install cython",
   "id": "29a36d4669817425",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cython in ./venv/lib/python3.9/site-packages (3.0.12)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T10:13:49.764076Z",
     "start_time": "2025-04-13T10:13:49.028638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n"
   ],
   "id": "e37eb21c68f5aa21",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edemmutalup/Desktop/semantic_changes/scripts/model_training/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T10:13:57.797185Z",
     "start_time": "2025-04-13T10:13:57.794428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "digits = {1: \"one\", 2: \"two\", 3: \"three\"}\n",
    "time = 2"
   ],
   "id": "66c5be6c258845e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T10:13:58.516581Z",
     "start_time": "2025-04-13T10:13:58.439362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = {\"fiction_and_blogs\": 0, \"fiction_and_news\": 0}\n",
    "\n",
    "for type in data:\n",
    "    tmp_data = []\n",
    "    for i in range(time):\n",
    "        json_file_path = f\"../../processed_data_upgraded/training_data/{type}_datum_{digits[i + 1]}.json\"\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "            datum = json.load(f)\n",
    "        tmp_data.append(datum)\n",
    "    data[type] = tmp_data"
   ],
   "id": "37bd2fac94f5b0e3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T10:14:00.848472Z",
     "start_time": "2025-04-13T10:14:00.843411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def quality_research(data, ep_diap):\n",
    "\n",
    "    qual = {\"fiction_and_blogs\": [], \"fiction_and_news\": []}\n",
    "\n",
    "    for type in qual:\n",
    "\n",
    "        for i in range(time):\n",
    "            scores = [[], [], []]\n",
    "            for ep in range(*ep_diap):\n",
    "                model = Word2Vec(\n",
    "                sentences=data[type][i],\n",
    "                vector_size=300,\n",
    "                window=4,\n",
    "                min_count=3,\n",
    "                sg=1,\n",
    "                workers=6,\n",
    "                epochs=ep\n",
    "                )\n",
    "                similarity_score = model.wv.evaluate_word_pairs(\"../../raw_data/wordsim353-russian.txt\")\n",
    "                pearson_result, spearman_result = similarity_score[0][0], similarity_score[1][0]\n",
    "                scores[0].append(ep)\n",
    "                scores[1].append(pearson_result)\n",
    "                scores[2].append(spearman_result)\n",
    "\n",
    "            qual[type].append(scores)\n",
    "\n",
    "    return qual"
   ],
   "id": "fd10a52f34a62062",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T10:42:05.256433Z",
     "start_time": "2025-04-13T10:16:42.524157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ep_range = (10, 200, 5)\n",
    "\n",
    "quality = quality_research(data, ep_range)"
   ],
   "id": "89e1c7be133587b6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T10:44:30.970532Z",
     "start_time": "2025-04-13T10:44:30.966830Z"
    }
   },
   "cell_type": "code",
   "source": "len(quality[\"fiction_and_news\"][0][0])",
   "id": "906354926c20260c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T10:47:34.984435Z",
     "start_time": "2025-04-13T10:47:34.979056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_quot = {\"fiction_and_blogs\": [], \"fiction_and_news\": []}\n",
    "\n",
    "for type in min_quot:\n",
    "    for idx in range(time):\n",
    "        size = len(quality[type][idx][0])\n",
    "        tmp = []\n",
    "        for i in range(size):\n",
    "            val = min(quality[type][idx][1][i], quality[type][idx][2][i])\n",
    "            tmp.append(val)\n",
    "        min_quot[type].append(tmp)\n"
   ],
   "id": "b479ffb7d341488f",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T10:53:57.523566Z",
     "start_time": "2025-04-13T10:53:57.516373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "avg_quot = {\"fiction_and_blogs\": [], \"fiction_and_news\": []}\n",
    "\n",
    "for type in avg_quot:\n",
    "    for idx in range(time):\n",
    "        size = len(quality[type][idx][0])\n",
    "        tmp = []\n",
    "        for i in range(size):\n",
    "            val = (quality[type][idx][1][i] + quality[type][idx][2][i]) / 2.0\n",
    "            tmp.append(val)\n",
    "        avg_quot[type].append(tmp)\n"
   ],
   "id": "a9b92b92309ac707",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T10:54:00.585037Z",
     "start_time": "2025-04-13T10:54:00.580291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(x_values, y_values, title=\"График\", xlabel=\"X\", ylabel=\"Y\", output_path=\"pic\"):\n",
    "\n",
    "    plt.figure(figsize=(10, 6), dpi=300)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "\n",
    "    plt.plot(x_values, y_values, marker='o', linestyle='-', color='blue')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    full_output_path = \"../../processed_data_upgraded/pics/Качество корпуса от количества эпох\" + output_path + \".png\"\n",
    "\n",
    "    output_dir = os.path.dirname(full_output_path)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    plt.savefig(full_output_path, bbox_inches='tight')\n",
    "    plt.close()\n"
   ],
   "id": "63f58b4a7f09aa3f",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T10:54:03.115688Z",
     "start_time": "2025-04-13T10:54:03.112634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dict_for_title = {\"fiction_and_blogs\": \"Худож. литература + Блоги\", \"fiction_and_news\": \"Худож. литература + ЧасКор (новости)\"}\n",
    "dict_for_time = {0: \"до 2000\", 1: \"с 2000 по 2015\"}"
   ],
   "id": "ac97c6e235bb1e4e",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T10:55:03.378006Z",
     "start_time": "2025-04-13T10:55:02.630080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for type in min_quot:\n",
    "    for idx in range(time):\n",
    "        plot_graph(quality[type][idx][0],\n",
    "                   avg_quot[type][idx],\n",
    "                   title=dict_for_title[type] + \" \" + dict_for_time[idx],\n",
    "                   xlabel=\"Эпохи\",\n",
    "                   ylabel=\"Среднее коэффициентов Пирсона и Спирмена\",\n",
    "                   output_path=dict_for_title[type] + \" \" + dict_for_time[idx] + \" среднее\")\n"
   ],
   "id": "de3c7d49e3559803",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T10:50:24.153223Z",
     "start_time": "2025-04-13T10:50:24.147998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(f\"../../processed_data_upgraded/quality_of_training.json\", 'w', encoding='utf-8') as file:\n",
    "        json.dump(quality, file, ensure_ascii=False, indent=2)"
   ],
   "id": "db2375d9a8696dcd",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "На основе графиков, можно сделать вывод, что самое удачное количество эпох для Худож. литература + ЧасКор (новости) в период до 2000 - 185, в период с 2000 по 2015 - 140",
   "id": "c3d2c660760c4c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:11:51.861771Z",
     "start_time": "2025-04-13T11:11:36.995374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_until2000 = Word2Vec(\n",
    "            sentences=data[\"fiction_and_news\"][0],\n",
    "            vector_size=300,\n",
    "            window=4,\n",
    "            min_count=3,\n",
    "            sg=1,\n",
    "            workers=6,\n",
    "            epochs=185\n",
    "            )"
   ],
   "id": "394fd5cc08bb8965",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:12:50.855447Z",
     "start_time": "2025-04-13T11:12:26.254897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_after2000 = Word2Vec(\n",
    "            sentences=data[\"fiction_and_news\"][1],\n",
    "            vector_size=300,\n",
    "            window=4,\n",
    "            min_count=3,\n",
    "            sg=1,\n",
    "            workers=6,\n",
    "            epochs=140\n",
    "            )"
   ],
   "id": "c39d44a7f1026530",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:16:44.869999Z",
     "start_time": "2025-04-13T11:16:44.831510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_until2000.save(f\"../../processed_data_upgraded/models/model_until2000.model\")\n",
    "model_after2000.save(f\"../../processed_data_upgraded/models/model_after2000.model\")"
   ],
   "id": "113acac8053ef8e2",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:12:53.000581Z",
     "start_time": "2025-04-13T11:12:52.988134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "similarity_score = model_after2000.wv.evaluate_word_pairs(\"../../raw_data/wordsim353-russian.txt\")\n",
    "pearson_result, spearman_result = similarity_score[0][0], similarity_score[1][0]\n",
    "print(pearson_result, spearman_result)"
   ],
   "id": "a0bce8f8c0ec3ecd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3409034748075943 0.3497793162105742\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:19:53.005789Z",
     "start_time": "2025-04-13T11:19:53.001935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def align_embeddings(model1, model2, common_vocab):\n",
    "    \"\"\"\n",
    "    Выравнивает эмбеддинги модели model1 относительно модели model2 на основе общего словаря.\n",
    "\n",
    "    Аргументы:\n",
    "      model1: gensim-модель (или её KeyedVectors), которую нужно преобразовать.\n",
    "      model2: gensim-модель (или её KeyedVectors), относительно которой производится выравнивание.\n",
    "      common_vocab: список слов, присутствующих в обеих моделях.\n",
    "\n",
    "    Возвращает:\n",
    "      R: матрица преобразования, которую можно применить ко всем векторным представлениям model1.\n",
    "    \"\"\"\n",
    "    # Формируем матрицы векторов из общего словаря\n",
    "    X = np.array([model1.wv[word] for word in common_vocab])\n",
    "    Y = np.array([model2.wv[word] for word in common_vocab])\n",
    "\n",
    "    # Вычисляем матрицу R, решающую задачу Orthogonal Procrustes\n",
    "    R, _ = orthogonal_procrustes(X, Y)\n",
    "    return R"
   ],
   "id": "1df943cd877f52f0",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:19:53.426248Z",
     "start_time": "2025-04-13T11:19:53.423350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transform_model(model, R):\n",
    "    \"\"\"\n",
    "    Применяет матрицу преобразования R ко всем эмбеддингам модели (model.wv).\n",
    "    Обратите внимание: этот метод изменяет модель на месте.\n",
    "    \"\"\"\n",
    "    # Для gensim 4.x используем model.wv.index_to_key для итерации по словам\n",
    "    for word in model.wv.index_to_key:\n",
    "        model.wv[word] = np.dot(model.wv[word], R)"
   ],
   "id": "d05dc53ec00f5c7",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:21:21.389761Z",
     "start_time": "2025-04-13T11:21:16.426131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "common_vocab = [word for word in model_until2000.wv.index_to_key if word in model_after2000.wv]\n",
    "\n",
    "R = align_embeddings(model_until2000, model_after2000, common_vocab)\n",
    "R = align_embeddings(model_until2000, model_after2000, common_vocab)\n",
    "\n",
    "transform_model(model_until2000, R)"
   ],
   "id": "b077eb9f37bdd1ee",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:21:29.896298Z",
     "start_time": "2025-04-13T11:21:29.891426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_semantic_shift(model1, model2, common_vocab):\n",
    "    \"\"\"\n",
    "    Для каждого слова из общего словаря вычисляет косинусное сходство между\n",
    "    его вектором в model1 и вектором в model2.\n",
    "\n",
    "    :param model1: Выровненная gensim-модель для первого периода.\n",
    "    :param model2: Выровненная gensim-модель для второго периода.\n",
    "    :param common_vocab: Список слов, присутствующих в обеих моделях.\n",
    "    :return: Список кортежей (слово, косинусное сходство), отсортированный по возрастанию сходства.\n",
    "    \"\"\"\n",
    "    shifts = {}\n",
    "    for word in common_vocab:\n",
    "        # Получаем векторы для слова из обеих моделей\n",
    "        vec1 = model1.wv[word]\n",
    "        vec2 = model2.wv[word]\n",
    "        # Вычисляем косинусное сходство:\n",
    "        # Обратите внимание: функция cosine из scipy.spatial.distance возвращает расстояние,\n",
    "        # т.е. 0 - полностью совпадают, а 1 - полностью противоположны.\n",
    "        # Поэтому, чтобы получить сходство, можно использовать: sim = 1 - cosine(vec1, vec2)\n",
    "        sim = 1 - cosine(vec1, vec2)\n",
    "        shifts[word] = sim\n",
    "\n",
    "    # Сортируем слова по сходству (минимальное сходство означает наибольший сдвиг)\n",
    "    sorted_shifts = sorted(shifts.items(), key=lambda item: item[1])\n",
    "    return sorted_shifts"
   ],
   "id": "ac6ca16d71f1f771",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1d85b7acb23c3fe4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:32:07.093229Z",
     "start_time": "2025-04-13T14:32:07.073128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shifted_words = compute_semantic_shift(model_until2000, model_after2000, common_vocab)\n",
    "print(\"Наиболее изменившиеся слова:\")\n",
    "for word, sim in shifted_words[:10]:\n",
    "    if sim < 0.1: continue\n",
    "    print(f\"{word}: сходство {sim:.4f}\")"
   ],
   "id": "bdfc9fb127c98252",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "Наиболее изменившиеся слова:\n",
      "живопись: сходство 0.1549\n",
      "облегчение: сходство 0.2030\n",
      "меняться: сходство 0.2086\n",
      "подозревать: сходство 0.2095\n",
      "пожаловать: сходство 0.2147\n",
      "безумный: сходство 0.2229\n",
      "удалить: сходство 0.2264\n",
      "многое: сходство 0.2281\n",
      "вывозить: сходство 0.2299\n",
      "гений: сходство 0.2329\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:27:01.673834Z",
     "start_time": "2025-04-13T11:27:01.669348Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Общий словарь содержит {len(common_vocab)} слов.\")",
   "id": "69deb72a6e468651",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общий словарь содержит 2019 слов.\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:33:17.754236Z",
     "start_time": "2025-04-13T11:33:17.727452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "similar_words = (model_until2000.wv.most_similar(\"пол\", topn=10))\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ],
   "id": "cc7906f42fc51635",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "опершись: 0.4443\n",
      "торопливо: 0.4439\n",
      "обит: 0.4309\n",
      "потолок: 0.4169\n",
      "улечься: 0.4149\n",
      "взад: 0.4133\n",
      "штора: 0.4071\n",
      "наоборот: 0.4032\n",
      "готовить: 0.4018\n",
      "абажур: 0.3967\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:33:24.255225Z",
     "start_time": "2025-04-13T11:33:24.138071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "similar_words = (model_after2000.wv.most_similar(\"пол\", topn=10))\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ],
   "id": "e9bb6858ea550813",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "рон: 0.5251\n",
      "представительница: 0.4393\n",
      "ладно: 0.3914\n",
      "полезно: 0.3743\n",
      "саймон: 0.3645\n",
      "футболист: 0.3504\n",
      "слабый: 0.3484\n",
      "зураб: 0.3427\n",
      "живописный: 0.3387\n",
      "разбросан: 0.3379\n"
     ]
    }
   ],
   "execution_count": 66
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
