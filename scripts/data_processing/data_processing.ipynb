{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:32:49.164994Z",
     "start_time": "2025-04-13T00:32:49.158856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import string\n",
    "import json\n",
    "import os\n",
    "\n",
    "from jedi.inference.utils import to_list"
   ],
   "id": "84bf914751255aa",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Функция build_verb_to_inf по морфологическому словарю возвращает словарь, в котором в качестве ключа хранятся лемматизированные глаголы, а значениями являются соответствующие инфинитивы.",
   "id": "3b0b908559b8bf62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:32:49.186480Z",
     "start_time": "2025-04-13T00:32:49.177451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_verb_to_inf(dictionary_file):\n",
    "\n",
    "    tree = ET.parse(dictionary_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    lemma_info = {}\n",
    "\n",
    "    lemmata_section = root.find(\"lemmata\")\n",
    "    if lemmata_section is None:\n",
    "        return {}\n",
    "\n",
    "    for lemma_elem in lemmata_section.findall(\"lemma\"):\n",
    "\n",
    "        lemma_id_str = lemma_elem.get(\"id\")\n",
    "        if lemma_id_str is None:\n",
    "            continue\n",
    "        try:\n",
    "            lemma_id = int(lemma_id_str)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        l_elem = lemma_elem.find(\"l\")\n",
    "        if l_elem is None:\n",
    "            continue\n",
    "\n",
    "        lemma_text = l_elem.get(\"t\", \"\").strip()\n",
    "        if not lemma_text:\n",
    "            continue\n",
    "        g_elem = l_elem.find(\"g\")\n",
    "\n",
    "        if g_elem is None:\n",
    "            continue\n",
    "\n",
    "        gram = g_elem.get(\"v\", \"\").strip()\n",
    "        lemma_info[lemma_id] = (lemma_text, gram)\n",
    "\n",
    "    verb_to_inf= {}\n",
    "\n",
    "    for lem_id in sorted(lemma_info.keys()):\n",
    "        lemma_text, gram = lemma_info[lem_id]\n",
    "\n",
    "        if gram == \"VERB\":\n",
    "            next_id = lem_id\n",
    "            while(True):\n",
    "                next_id += 1\n",
    "                if next_id in lemma_info:\n",
    "                    next_text, next_gram = lemma_info[next_id]\n",
    "                    if next_gram == \"INFN\":\n",
    "\n",
    "                        verb_to_inf[lemma_text] = next_text\n",
    "                        break\n",
    "                    else:\n",
    "\n",
    "                        verb_to_inf[lemma_text] = lemma_text\n",
    "                    if next_gram != \"VERB\":\n",
    "                        break\n",
    "                else:\n",
    "\n",
    "                    verb_to_inf[lemma_text] = lemma_text\n",
    "\n",
    "\n",
    "    return verb_to_inf"
   ],
   "id": "f5366e6edb34facd",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:32:49.212421Z",
     "start_time": "2025-04-13T00:32:49.201249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dict_path = \"../../raw_data/dict.opcorpora.xml\"\n",
    "\n",
    "if (os.path.exists(\"../../processed_data/verb_to_inf.json\")):\n",
    "    with open(\"../../processed_data/verb_to_inf.json\", 'r', encoding='utf-8') as f:\n",
    "            verb_to_inf = json.load(f)\n",
    "else:\n",
    "    verb_to_inf = build_verb_to_inf(dict_path)\n"
   ],
   "id": "a5f62349fa6e50bb",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Подготовим xml-дерево и массивы для удобного взаимодействия с деревом",
   "id": "8bced9cbc9d2a13c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:32:49.226193Z",
     "start_time": "2025-04-13T00:32:49.224343Z"
    }
   },
   "cell_type": "code",
   "source": "file_path = \"../../raw_data/annot.opcorpora_upgraded.xml\"",
   "id": "fb475325cad98278",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:38:26.784481Z",
     "start_time": "2025-04-13T00:32:49.247711Z"
    }
   },
   "cell_type": "code",
   "source": "tree = ET.parse(file_path)",
   "id": "568c6f406f6c6d0d",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:09.734912Z",
     "start_time": "2025-04-13T00:40:09.730128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_adjacency_array():\n",
    "    root = tree.getroot()\n",
    "\n",
    "    adjacency_array = [[None]] * 5000\n",
    "\n",
    "    vertices = [None] * 5000\n",
    "\n",
    "    for text_elem in root.findall(\"text\"):\n",
    "        parent = int(text_elem.get(\"parent\"))\n",
    "        child = int(text_elem.get(\"id\"))\n",
    "        vertices[child] = text_elem\n",
    "        if adjacency_array[parent][0] is None:\n",
    "            adjacency_array[parent] = []\n",
    "        adjacency_array[parent].append(child)\n",
    "\n",
    "    return adjacency_array, vertices"
   ],
   "id": "62e1ed9c5b6ebbbc",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:10.012074Z",
     "start_time": "2025-04-13T00:40:09.990630Z"
    }
   },
   "cell_type": "code",
   "source": "adjacency_array, vertices = build_adjacency_array()",
   "id": "a681e8532237b2fc",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:10.195720Z",
     "start_time": "2025-04-13T00:40:10.191898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def expand(type_id):\n",
    "    sentences = []\n",
    "    for sentence in vertices[type_id].findall(\".//sentence\"):\n",
    "        tokens_elem = sentence.find(\"tokens\")\n",
    "        if tokens_elem is not None:\n",
    "            tokens_list = []\n",
    "            for token in tokens_elem.findall(\"token\"):\n",
    "                if token.find(\"tfr/v/l\") is not None and (\n",
    "                word := token.find(\"tfr/v/l\").attrib.get(\"t\")) not in stoplist:\n",
    "                    if token.find(\"tfr/v/l/g\") is not None and token.find(\"tfr/v/l/g\").attrib.get(\n",
    "                        \"v\") == \"VERB\":\n",
    "                        word = verb_to_inf[word]\n",
    "                    if any(char.isdigit() for char in word): continue\n",
    "                    tokens_list.append(word)\n",
    "        sentences.append(tokens_list)\n",
    "    return sentences"
   ],
   "id": "57128f6d648a909b",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:10.385171Z",
     "start_time": "2025-04-13T00:40:10.381818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stoplist = list(string.punctuation)\n",
    "additional_chars = ['…', '–', '—', '«', '»', '“', '”', '’', '‘']\n",
    "stop_words = [\n",
    "    # Предлоги\n",
    "    \"в\", \"во\", \"без\", \"для\", \"до\", \"за\", \"из\", \"изо\", \"к\", \"ко\",\n",
    "    \"на\", \"над\", \"о\", \"об\", \"обо\", \"от\", \"по\", \"под\", \"подо\",\n",
    "    \"при\", \"про\", \"с\", \"со\", \"через\", \"сквозь\", \"среди\", \"около\",\n",
    "\n",
    "    # Союзы\n",
    "    \"и\", \"а\", \"но\", \"либо\", \"или\", \"да\", \"однако\", \"зато\",\n",
    "    \"потому что\", \"так как\", \"поскольку\", \"как\", \"если\", \"когда\",\n",
    "    \"хотя\", \"ведь\", \"поэтому\", \"так что\", \"ибо\",\n",
    "\n",
    "    # Частицы\n",
    "    \"же\", \"бы\", \"ли\", \"разве\", \"только\", \"даже\", \"уж\", \"ну\", \"хоть\", \"-то\"\n",
    "]\n",
    "stoplist.extend(additional_chars)\n",
    "stoplist.extend(stop_words)"
   ],
   "id": "549cea7a11b5fae7",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:10.567443Z",
     "start_time": "2025-04-13T00:40:10.563845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def corpus_filtering(type_id, begin, end, year = None):\n",
    "    corpus = []\n",
    "    tags_elem = vertices[type_id].find(\"tags\")\n",
    "    if tags_elem is not None:\n",
    "\n",
    "        for tag in tags_elem.findall(\"tag\"):\n",
    "            tag_text = tag.text\n",
    "            if tag_text and tag_text.startswith(\"Год:\"):\n",
    "                try:\n",
    "                    year = int(tag_text.split(\"Год:\")[-1].strip())\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                break\n",
    "\n",
    "    for child in adjacency_array[type_id]:\n",
    "\n",
    "        if child is None:\n",
    "            if year is not None and (begin <= year < end):\n",
    "                corpus = expand(type_id)\n",
    "            return corpus\n",
    "\n",
    "        corpus.extend(corpus_filtering(child, begin, end, year))\n",
    "\n",
    "\n",
    "    return corpus"
   ],
   "id": "68fe69f078c9c53f",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:10.857906Z",
     "start_time": "2025-04-13T00:40:10.855757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus_types = {\n",
    "    \"ЧасКор (новости)\" : 226,\n",
    "    \"Википедия\" : 8,\n",
    "    \"Блоги\" : 184,\n",
    "    \"Худож. литература\" : 806,\n",
    "    \"Нон-фикшн\" : 2037\n",
    "}"
   ],
   "id": "2c289c1cd79cc8aa",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:11.141710Z",
     "start_time": "2025-04-13T00:40:11.138972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def amount_of_words(corpus):\n",
    "    amount = 0\n",
    "    for sen in corpus:\n",
    "        amount += len(sen)\n",
    "    return amount"
   ],
   "id": "92130933d26c6bc7",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:15.613937Z",
     "start_time": "2025-04-13T00:40:11.477759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpora_stats = {}\n",
    "\n",
    "start_with = 1800\n",
    "end = 2020\n",
    "shift = 10\n",
    "\n",
    "for (type, id) in corpus_types.items():\n",
    "    quantity = 0\n",
    "    time_cutoffs = []\n",
    "    words = []\n",
    "    for year in range(start_with, end, shift):\n",
    "        tmp_corpus = corpus_filtering(id, year, year + shift)\n",
    "        words.append(amount_of_words(tmp_corpus))\n",
    "        time_cutoffs.append(year)\n",
    "    corpora_stats[type] = (time_cutoffs, words)\n"
   ],
   "id": "5bcda5b5e79545e8",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:15.620342Z",
     "start_time": "2025-04-13T00:40:15.618602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Union"
   ],
   "id": "c30d6bccf417a88b",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:15.636588Z",
     "start_time": "2025-04-13T00:40:15.631453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_word_counts(\n",
    "    x_data: List[Union[int, str]],\n",
    "    y_data: List[int],\n",
    "    output_path: str = \"word_counts_visualization.png\",\n",
    "    figsize: tuple = (12, 6),\n",
    "    dpi: int = 300,\n",
    "    show_values: bool = True,\n",
    "    rotation: int = 45\n",
    ") -> None:\n",
    "\n",
    "    if all(isinstance(x, int) for x in x_data):\n",
    "        sorted_data = sorted(zip(x_data, y_data), key=lambda pair: pair[0])\n",
    "        x_data, y_data = zip(*sorted_data)\n",
    "        x_data = [str(x) for x in x_data]\n",
    "    else:\n",
    "        x_data = [str(x) for x in x_data]\n",
    "\n",
    "    plt.figure(figsize=figsize, dpi=dpi)\n",
    "    bars = plt.bar(x_data, y_data, color='#1f77b4')\n",
    "\n",
    "    plt.title(f'Распределение количества слов типа текстов {output_path}', pad=20)\n",
    "    plt.xlabel('Десятилетие', labelpad=10)\n",
    "    plt.ylabel('Количество слов', labelpad=10)\n",
    "    plt.xticks(rotation=rotation, ha='right')\n",
    "    plt.grid(axis='y', linestyle=':', alpha=0.7)\n",
    "\n",
    "    if show_values:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                height,\n",
    "                f'{int(height):,}',\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontsize=8\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    output_path = \"../../processed_data_upgraded/pics/распределения слов \" + output_path + \".png\"\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Visualization saved to {output_path}\")"
   ],
   "id": "14f76f63577175ff",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:16.941588Z",
     "start_time": "2025-04-13T00:40:15.648413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for (type, (decades, words)) in corpora_stats.items():\n",
    "    visualize_word_counts(decades, words, output_path=type)"
   ],
   "id": "d84bb8aae410f2f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to ../../processed_data_upgraded/pics/распределения слов ЧасКор (новости).png\n",
      "Visualization saved to ../../processed_data_upgraded/pics/распределения слов Википедия.png\n",
      "Visualization saved to ../../processed_data_upgraded/pics/распределения слов Блоги.png\n",
      "Visualization saved to ../../processed_data_upgraded/pics/распределения слов Худож. литература.png\n",
      "Visualization saved to ../../processed_data_upgraded/pics/распределения слов Нон-фикшн.png\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Изучив данные, становится понятно, что для исследования семантических сдвигов, мы должны взять Худож. литература, ибо другие типы не предоставляют достаточного количества данных до 21 века.\n",
    "\n",
    "\n",
    "Для выбора второй выборки проведем сравнение, исследуем сумму слов для каждого типа + Худож. литература"
   ],
   "id": "386b30caa502afb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:20.873Z",
     "start_time": "2025-04-13T00:40:20.869518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sum_arr(first, second):\n",
    "    length = len(first)\n",
    "    res = [0] * length\n",
    "    for i in range(length):\n",
    "        res[i] = first[i] + second[i]\n",
    "    return res"
   ],
   "id": "9588917c7e33fa0c",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:22.157634Z",
     "start_time": "2025-04-13T00:40:21.120675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lit_type = \"Худож. литература\"\n",
    "lit_word = corpora_stats[lit_type][1]\n",
    "\n",
    "for (type, (decades, words)) in corpora_stats.items():\n",
    "    if type == lit_type: continue\n",
    "    visualize_word_counts(decades, sum_arr(words, lit_word), output_path=(\"суммы \" + lit_type + \" и \" + type))"
   ],
   "id": "c58a9e5391c03e00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to ../../processed_data_upgraded/pics/распределения слов суммы Худож. литература и ЧасКор (новости).png\n",
      "Visualization saved to ../../processed_data_upgraded/pics/распределения слов суммы Худож. литература и Википедия.png\n",
      "Visualization saved to ../../processed_data_upgraded/pics/распределения слов суммы Худож. литература и Блоги.png\n",
      "Visualization saved to ../../processed_data_upgraded/pics/распределения слов суммы Худож. литература и Нон-фикшн.png\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Из полученных графиков, можно определить, что разбиение на 3 периода осмысленно, только в случае:\n",
    "1. до 2000 года\n",
    "2. с 2000 по 2010\n",
    "3. с 2010 по 2020\n",
    "\n",
    "Для такой кластеризации подойдут наборы данных Худож. литература + Блоги и Худож. литература + ЧасКор (новости)"
   ],
   "id": "8f6616f68a5516a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Составим соответствующие корпуса текстов",
   "id": "3a103887629130f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:25.865996Z",
     "start_time": "2025-04-13T00:40:25.862131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def periods_calc(type, periods):\n",
    "    length = len(periods)\n",
    "    data = [0] * length\n",
    "    for i in range(length):\n",
    "        data[i] = corpus_filtering(corpus_types[type], *periods[i])\n",
    "    return data"
   ],
   "id": "12a2eab3c8f103d",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:28.739723Z",
     "start_time": "2025-04-13T00:40:26.369147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fiction_and_blogs = {}\n",
    "fiction_and_news = {}\n",
    "\n",
    "fiction_type = \"Худож. литература\"\n",
    "blogs_type = \"Блоги\"\n",
    "news_type = \"ЧасКор (новости)\"\n",
    "\n",
    "periods = [(1800, 2000), (2000, 2015)]\n",
    "\n",
    "fiction_data = periods_calc(fiction_type, periods)\n",
    "blogs_data = periods_calc(blogs_type, periods)\n",
    "news_data = periods_calc(news_type, periods)\n",
    "\n",
    "times = len(periods)\n",
    "\n",
    "for i in range(times):\n",
    "    fiction_and_blogs[periods[i]] = fiction_data[i] + blogs_data[i]\n",
    "    fiction_and_news[periods[i]] = fiction_data[i] + news_data[i]\n"
   ],
   "id": "b1f1295a079b2300",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:38:42.140788Z",
     "start_time": "2025-04-13T00:38:42.139250Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "58c67f6c9ce0f658",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Сохраним полученные данные",
   "id": "b9dd55e54348bb6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:31.101242Z",
     "start_time": "2025-04-13T00:40:31.098953Z"
    }
   },
   "cell_type": "code",
   "source": "import json",
   "id": "39bfb20636c8fa6",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:31.500575Z",
     "start_time": "2025-04-13T00:40:31.498418Z"
    }
   },
   "cell_type": "code",
   "source": "digits = {1: \"one\", 2: \"two\", 3: \"three\"}",
   "id": "7c302ae2c2f5832e",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:40:32.244035Z",
     "start_time": "2025-04-13T00:40:32.082058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(times):\n",
    "    with open(f\"../../processed_data_upgraded/training_data/fiction_and_blogs_datum_{digits[i + 1]}.json\", 'w', encoding='utf-8') as file:\n",
    "        json.dump(fiction_and_blogs[periods[i]], file, ensure_ascii=False, indent=2)\n",
    "\n",
    "    with open(f\"../../processed_data_upgraded/training_data/fiction_and_news_datum_{digits[i + 1]}.json\", 'w', encoding='utf-8') as file:\n",
    "        json.dump(fiction_and_news[periods[i]], file, ensure_ascii=False, indent=2)"
   ],
   "id": "8549df59b54dd7f9",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:38:42.433572Z",
     "start_time": "2025-04-13T00:38:42.431888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for i in range(times):\n",
    "#     with open(f\"../../processed_data_upgraded/training_data/fiction_and_blogs_datum_{digits[i + 1]}.cor\", 'w', encoding='utf-8') as file:\n",
    "#         for tokens in fiction_and_blogs[periods[i]]:\n",
    "#             line = \" \".join(tokens)\n",
    "#             file.write(line + \"\\n\")\n",
    "#\n",
    "#     with open(f\"../../processed_data_/training_data/fiction_and_news_datum_{digits[i + 1]}.cor\", 'w', encoding='utf-8') as file:\n",
    "#         for tokens in fiction_and_news[periods[i]]:\n",
    "#             line = \" \".join(tokens)\n",
    "#             file.write(line + \"\\n\")"
   ],
   "id": "b7d2698ff8abcfea",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Также сохраним словарь verb_to_inf",
   "id": "93e57e60ab0ba9ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:38:42.470635Z",
     "start_time": "2025-04-13T00:38:42.444727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"../../processed_data/verb_to_inf.json\", 'w', encoding='utf-8') as file:\n",
    "    json.dump(verb_to_inf, file, ensure_ascii=False, indent=2)"
   ],
   "id": "76292cbd06dd70fe",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:38:42.482867Z",
     "start_time": "2025-04-13T00:38:42.481280Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "305906e15cea0ff5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T00:38:42.497714Z",
     "start_time": "2025-04-13T00:38:42.494992Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3c8a2efb470db6e9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
